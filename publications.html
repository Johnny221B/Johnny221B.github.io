<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>Publications - Yuzhe Yang</title>
    <meta name="author" content="Yuzhe Yang" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" type="text/css" href="src/stylesheet.css" />
    <link rel="icon" href="./src/logo/CUHK_rm_bg.png" type="image/x-icon" />
    <!-- Google Fonts for handwriting style and rounded fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400;500;600;700&family=Nunito:ital,wght@0,200..1000;1,200..1000&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
    <!-- Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-YE837RNHM5"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-YE837RNHM5");
    </script>
  </head>

  <body>
    <table class="main-container">
      <tbody>
        <tr class="zero-padding">
          <td class="zero-padding">
            <!-- Back to Home Link -->
            <div style="text-align: center; margin-bottom: 30px;">
              <a href="index.html" style="font-size: 16px; font-weight: 500;">‚Üê Back to Home</a>
            </div>

            <!-- Publications Section -->
            <table id="publications" class="content-table">
              <tbody>
                <tr>
                  <td class="section-padding">
                    <heading>Publications</heading>
                    <p style="color: gray;">(* indicates equal contribution)</p>

                    <table class="content-table">
                      
                      <tr>
                        <td colspan="2" class="year-divider">
                          <hr>
                          <span class="year-label">2025</span>
                        </td>
                      </tr>
                      
                      <!-- TwinMarket Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/TwinMarket.jpg" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets</papertitle>
                          <br />
                          <b>Yuzhe Yang*</b>, Yifei Zhang*, Minghao Wu*, Kaidi Zhang, Yunmiao Zhang, Honghai Yu, Yan Hu, Benyou Wang
                          <br />
                          <em>Proceedings of NeurIPS 2025</em>
                          <br />
                          <a href="./src/img/best_paper.jpg"><b>Best Paper Award</b></a>, <em>ICLR 2025 Workshop on Advances in Financial AI</em>
                          <br />
                          A multi-agent framework that leverages LLMs to simulate socio-economic systems
                          <br />
                          <a href="https://arxiv.org/abs/2502.01506">Paper</a> /
                          <a href="https://github.com/FreedomIntelligence/TwinMarket">Code</a> /
                          <a href="https://freedomintelligence.github.io/TwinMarket/">Project Page</a>
                          <p></p>
                        </td>
                      </tr>

                      <!-- EvoPresent Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/EvoPresent.png" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations</papertitle>
                          <br />
                          Chengzhi Liu*, <b>Yuzhe Yang*</b>, Kaiwen Zhou, Zhen Zhang, Yue Fan, Yannan Xie, Peng Qi, Xin Eric Wang
                          <br />
                          <em>arXiv preprint 2025</em>
                          <br />
                          A self-improvement agent generating presentation videos from academic papers
                          <br />
                          <a href="https://arxiv.org/abs/2510.05571">Paper</a> / <a href="https://github.com/eric-ai-lab/EvoPresent">Code</a> / <a href="https://evopresent.github.io/">Project Page</a>
                          <p></p>
                        </td>
                      </tr>

                      <!-- UCFE Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/UCFE.png" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</papertitle>
                          <br />
                          <b>Yuzhe Yang*</b>, Yifei Zhang*, Yan Hu*, Yilin Guo, Ruoli Gan, Yueru He, Mingcong Lei, Xiao Zhang, Haining Wang, Qianqian Xie, Jimin Huang, Honghai Yu, Benyou Wang
                          <br />
                          <em>Findings of NAACL 2025</em>
                          <br />
                          <a href="https://huggingface.co/papers?date=2024-10-21">#1 Paper of the day on Huggingface</a>
                          <br />
                          A User-Centric framework designed to evaluate LLMs' ability to handle complex financial tasks
                          <br />
                          <a href="https://aclanthology.org/2025.findings-naacl.300/">Paper</a> /
                          <a href="https://github.com/TobyYang7/UCFE-Benchmark">Code</a> /
                          <a href="https://huggingface.co/datasets/TobyYang7/UCFE">Dataset</a>
                          <p></p>
                        </td>
                      </tr>

                    <!-- SAE-free -->
                    <tr class="publication-row">
                      <td class="publication-image">
                        <img src="./src/img/sae_free.png" width="100%" />
                      </td>
                      <td class="publication-content">
                        <papertitle>Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models</papertitle>
                        <br />
                        Zihao Li*, Xu Wang*, <b>Yuzhe Yang</b>, Ziyu Yao, Haoyi Xiong, Mengnan Du
                        <br />
                        <em>Proceedings of EMNLP 2025</em>
                        <br />
                        Enhance LLM reasoning by steering activations via a novel SAE-free method using Chain-of-Thought features, without external data
                        <br />
                        <a href="https://arxiv.org/abs/2505.15634">Paper</a>
                        <p></p>
                      </td>
                    </tr>

                      <!-- OSCAR Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/OSCAR.png" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching</papertitle>
                          <br />
                          Jingxuan Wu*, Zhenglin Wan*, Xingrui Yu, <b>Yuzhe Yang</b>, Bo An, Ivor Tsang
                          <br />
                          <em>arXiv preprint 2025</em>
                          <br />
                          Training-free diversity enhancement for flow-based text-to-image models via orthogonal stochastic control
                          <br />
                          <a href="https://arxiv.org/abs/2510.09060">Paper</a> /
                          <a href="https://github.com/Johnny221B/OSCAR">Code</a>
                          <p></p>
                        </td>
                      </tr>

                      <!-- FDPT Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/FDPT.png" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>FDPT: Federated Discrete Prompt Tuning for Black-Box Visual-Language Models</papertitle>
                          <br />
                          Jiaqi Wu, Simin Chen, Jing Tang, <b>Yuzhe Yang</b>, Yiming Chen, Lixu Wang, Song Lin, Zehua Wang, Wei Chen, Zijian Tian
                          <br />
                          <em>Proceedings of ICCV 2025</em>
                          <br />
                          Federated prompt tuning approach for black-box visual-language models
                          <br />
                          <a href="#">Paper</a>
                          <p></p>
                        </td>
                      </tr>

                      <tr>
                        <td colspan="2" class="year-divider">
                          <hr>
                          <span class="year-label">2024</span>
                        </td>
                      </tr>

                      <!-- Open-FinLLMs Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/finllava.png" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications</papertitle>
                          <br />
                          Jimin Huang, Mengxi Xiao, Dong Li, Zihao Jiang, <b>Yuzhe Yang (lead multimodal training)</b>, Yifei Zhang, Lingfei Qian, Yan Wang, Xueqing Peng, Yang Ren, Ruoyu Xiang, Zhengyu Chen, Xiao Zhang, Yueru He, Weiguang Han, Shunian Chen, Lihang Shen, Daniel Kim, Yangyang Yu, Yupeng Cao, Zhiyang Deng, Haohang Li, Duanyu Feng, Yongfu Dai, VijayaSai Somasundaram, Peng Lu, Guojun Xiong, Zhiwei Liu, Zheheng Luo, Zhiyuan Yao, Ruey-Ling Weng, Meikang Qiu, Kaleb E Smith, Honghai Yu, Yanzhao Lai, Min Peng, Jian-Yun Nie, Jordan W. Suchow, Xiao-Yang Liu, Benyou Wang, Alejandro Lopez-Lira, Qianqian Xie, Sophia Ananiadou, Junichi Tsujii
                          <br />
                          <em>arXiv preprint 2024</em>
                          <br />
                          First open-source financial multimodal LLM: FinLLaVA-8B
                          <br />
                          <a href="https://arxiv.org/abs/2408.11878">Paper</a> /
                          <a href="https://huggingface.co/TheFinAI/FinLLaVA">Model</a>
                          <p></p>
                        </td>
                      </tr>

                      <!-- FAST-CA Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/FAST-CA.jpg" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>FAST-CA: Fusion-based Adaptive Spatial-Temporal Learning with Coupled Attention for airport network delay propagation prediction</papertitle>
                          <br />
                          Chi Li, Xixian Qi, <b>Yuzhe Yang</b>, Zhuo Zeng, Lianmin Zhang, Jianfeng Mao
                          <br />
                          <em>Information Fusion 2024</em>
                          <br />
                          SOTA spatio-temporal model for predicting airport network delay propagation
                          <br />
                          <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253524001040">Paper</a>
                          <p></p>
                        </td>
                      </tr>

                      <!-- FedDTPT Publication -->
                      <tr class="publication-row">
                        <td class="publication-image">
                          <img src="./src/img/feddtpt.png" width="100%" />
                        </td>
                        <td class="publication-content">
                          <papertitle>FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models</papertitle>
                          <br />
                          Jiaqi Wu, Simin Chen, <b>Yuzhe Yang</b>, Yijiang Li, Shiyue Hou, Rui Jing, Zehua Wang, Wei Chen, Zijian Tian
                          <br />
                          <em>arXiv preprint 2024</em>
                          <br />
                          A federated prompt tuning method for black-box LLMs, enhancing privacy, efficiency, and performance on non-iid data
                          <br />
                          <a href="https://arxiv.org/abs/2411.00985">Paper</a>
                          <p></p>
                        </td>
                      </tr>
                    </table>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Footer Section -->
            <table class="content-table">
              <tbody>
                <tr>
                  <td class="zero-padding">
                    <br />
                    <div class="footer-center">
                      <script
                        type="text/javascript"
                        id="clustrmaps"
                        src="//cdn.clustrmaps.com/map_v2.js?cl=5ab2ff&w=300&t=tt&d=xoDg7VaCrLXmmLZN9tIoONrsj5uu62Bt8Fx4GVA9cuM&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353"
                      ></script>
                    </div>
                    <p class="footer-text">
                      2024-2025 ¬©Ô∏è Yuzhe Yang
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html> 