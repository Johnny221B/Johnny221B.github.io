@misc{yang2025twinmarketscalablebehavioralsocial,
      title={TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets}, 
      author={Yuzhe Yang and Yifei Zhang and Minghao Wu and Kaidi Zhang and Yunmiao Zhang and Honghai Yu and Yan Hu and Benyou Wang},
      year={2025},
      eprint={2502.01506},
      archivePrefix={arXiv},
      primaryClass={cs.CE},
      url={https://arxiv.org/abs/2502.01506}, 
}

@inproceedings{yang-etal-2025-ucfe,
    title = "{UCFE}: A User-Centric Financial Expertise Benchmark for Large Language Models",
    author = "Yang, Yuzhe  and
      Zhang, Yifei  and
      Hu, Yan  and
      Guo, Yilin  and
      Gan, Ruoli  and
      He, Yueru  and
      Lei, Mingcong  and
      Zhang, Xiao  and
      Wang, Haining  and
      Xie, Qianqian  and
      Huang, Jimin  and
      Yu, Honghai  and
      Wang, Benyou",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.300/",
    pages = "5429--5448",
    ISBN = "979-8-89176-195-7",
    abstract = "This paper introduces the UCFE: User-Centric Financial Expertise benchmark, an innovative framework designed to evaluate the ability of large language models (LLMs) to handle complex real-world financial tasks. UCFE benchmark adopts a hybrid approach that combines human expert evaluations with dynamic, task-specific interactions to simulate the complexities of evolving financial scenarios. Firstly, we conducted a user study involving 804 participants, collecting their feedback on financial tasks. Secondly, based on this feedback, we created our dataset that encompasses a wide range of user intents and interactions. This dataset serves as the foundation for benchmarking 11 LLMs services using the LLM-as-Judge methodology. Our results show a significant alignment between benchmark scores and human preferences, with a Pearson correlation coefficient of 0.78, confirming the effectiveness of the UCFE dataset and our evaluation approach. UCFE benchmark not only reveals the potential of LLMs in the financial domain but also provides a robust framework for assessing their performance and user satisfaction."
}

@misc{huang2025openfinllmsopenmultimodallarge,
      title={Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications}, 
      author={Jimin Huang and Mengxi Xiao and Dong Li and Zihao Jiang and Yuzhe Yang and Yifei Zhang and Lingfei Qian and Yan Wang and Xueqing Peng and Yang Ren and Ruoyu Xiang and Zhengyu Chen and Xiao Zhang and Yueru He and Weiguang Han and Shunian Chen and Lihang Shen and Daniel Kim and Yangyang Yu and Yupeng Cao and Zhiyang Deng and Haohang Li and Duanyu Feng and Yongfu Dai and VijayaSai Somasundaram and Peng Lu and Guojun Xiong and Zhiwei Liu and Zheheng Luo and Zhiyuan Yao and Ruey-Ling Weng and Meikang Qiu and Kaleb E Smith and Honghai Yu and Yanzhao Lai and Min Peng and Jian-Yun Nie and Jordan W. Suchow and Xiao-Yang Liu and Benyou Wang and Alejandro Lopez-Lira and Qianqian Xie and Sophia Ananiadou and Junichi Tsujii},
      year={2025},
      eprint={2408.11878},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.11878}, 
}

@article{LI2024102326,
title = {FAST-CA: Fusion-based Adaptive Spatial–Temporal Learning with Coupled Attention for airport network delay propagation prediction},
journal = {Information Fusion},
volume = {107},
pages = {102326},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102326},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524001040},
author = {Chi Li and Xixian Qi and Yuzhe Yang and Zhuo Zeng and Lianmin Zhang and Jianfeng Mao},
keywords = {Graph neural networks, Flight delay prediction, Delay propagation, Dynamic graph, Adaptive learning},
abstract = {The issue of delay propagation prediction in airport networks has garnered increasing global attention, particularly due to its profound impact on operational efficiency and passenger satisfaction in modern air transportation systems. Despite research advancements in this domain, existing methodologies often fall short of comprehensively addressing the challenges associated with predicting delay propagation in airport networks, especially in terms of handling complex spatial–temporal dependencies and sequence couplings. In response to the complex challenge of predicting delay propagation in airport networks, we introduce the Fusion-based Adaptive Spatial–Temporal Learning with Coupled Attention (FAST-CA) framework. FAST-CA is an innovative model that integrates dynamic and adaptive graph learning, coupled attention mechanisms, periodicity feature extraction, and multifaceted information fusion modules. This holistic approach enables a thorough analysis of the interplay between flight departure and arrival delays and the spatial–temporal correlations within airport networks. Rigorously evaluated on two extensive real-world datasets, our model consistently outperforms current state-of-the-art baseline models, showcasing superior predictive performance and the effective learning capabilities of its intricately designed modules. Our research highlights the criticality of analyzing spatial–temporal relationships and the dynamics of flight coupling, offering significant theoretical and practical contributions to the advancement and management of air transportation systems.}
}

@misc{wu2024feddtptfederateddiscretetransferable,
      title={FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models}, 
      author={Jiaqi Wu and Simin Chen and Yuzhe Yang and Yijiang Li and Shiyue Hou and Rui Jing and Zehua Wang and Wei Chen and Zijian Tian},
      year={2024},
      eprint={2411.00985},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.00985}, 
}